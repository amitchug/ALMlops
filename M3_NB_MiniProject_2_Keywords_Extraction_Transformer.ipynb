{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitchug/ALMlops/blob/main/M3_NB_MiniProject_2_Keywords_Extraction_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Mini-Project: Keywords Extraction using Transformer"
      ],
      "metadata": {
        "id": "LJY-HzQzCiJx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNCzT95pcrIN"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMBrLtAtcrIO"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* perform data preprocessing, EDA and feature extraction on the Medical Transcription dataset\n",
        "* build transformer components - positional embedding, encoder, decoder, etc\n",
        "* train a transformer model for keywords extraction\n",
        "* create function to perform inference using trained transformer\n",
        "* use the gradio library  to generate a customizable UI for displaying the extracted keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Xda9CM9el9"
      },
      "source": [
        "## Dataset description"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used in this project is the **Medical transcription** dataset. It contains sample medical transcriptions for various medical specialties.\n",
        "\n",
        "The data is in CSV format with below features:\n",
        "\n",
        "- **description**\n",
        "\n",
        "- **medical_specialty**\n",
        "\n",
        "- **sample_name**\n",
        "\n",
        "- **transcription**\n",
        "\n",
        "- **keywords**"
      ],
      "metadata": {
        "id": "i98dvBWFQq4x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ZV5ryMP07f"
      },
      "source": [
        "##  Grading = 10 Points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pped-3NPaDV"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuxYf07d62Oo"
      },
      "source": [
        "Medical transcriptions are textual records of patient-doctor interactions, medical procedures, clinical findings, and more. Extracting keywords from these transcriptions can provide valuable insights into a patient's health status, medical history, and treatment plans.\n",
        "\n",
        "* Significance:\n",
        "\n",
        "  - Data Summarization: Keyword extraction helps in summarizing lengthy medical transcriptions, making it easier for healthcare professionals to quickly understand the patient's medical history.\n",
        "\n",
        "  - Search and Retrieval: Extracted keywords can be used to index medical records, facilitating faster search and retrieval of relevant documents.\n",
        "\n",
        "  - Trend Analysis: By analyzing frequently occurring keywords, healthcare institutions can identify common ailments, treatment outcomes, and more.\n",
        "\n",
        "* Applications:\n",
        "\n",
        "  - Clinical Decision Support: Extracted keywords can be used to develop clinical decision support systems that provide real-time suggestions to healthcare professionals.\n",
        "  - Patient Monitoring: By continuously analyzing the keywords from a patient's medical transcriptions, healthcare systems can monitor the patient's health and predict potential health risks.\n",
        "  - Research: Medical researchers can use extracted keywords to identify trends, study disease outbreaks, and understand treatment efficacies.\n",
        "  - Billing and Insurance: Keywords can help in automating the medical coding process, which is essential for billing and insurance claims."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement"
      ],
      "metadata": {
        "id": "YN15WtbfwPkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a transformer model for performing keywords extraction on medical transcription dataset.\n",
        "\n",
        "**Note:**\n",
        "> For some steps such as how to create a positional embedding layer, transformer components - encoder and decoder blocks, etc you may need to refer to the ***M3 Assignment-5 on Transformer_Decoder***."
      ],
      "metadata": {
        "id": "R8_CoX7swR14"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt9VG5y7FLpv"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV7FBip_FLpw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "from string import digits\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the dataset\n",
        "!wget -q https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/Medical_transcription_dataset.csv\n",
        "!ls | grep \".csv\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "_LAPs1EOmaID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3FkLI6wcaat"
      },
      "source": [
        "**Exercise 1: Read the Medical_transcription_dataset.csv dataset**\n",
        "\n",
        "**Hint:** pd.read_csv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "zvi5Q_4GVZwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvddL7X69NiB"
      },
      "source": [
        "### Pre-processing and EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: Perform below operations on the dataset [0.5 Mark]**\n",
        "\n",
        "- Remove unnecessary columns - 'Unnamed: 0'\n",
        "- Handle missing values\n",
        "- Remove rows from data where `keywords` is only single empty space ' $ $ '\n",
        "- Remove duplicates from data considering `transcription` and `keywords` columns\n"
      ],
      "metadata": {
        "id": "xgB7KCn88Vmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove unnecessary columns - 'Unnamed: 0'**"
      ],
      "metadata": {
        "id": "0KpssAWUBiok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "FNo5NyBhFpmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Handle missing values**"
      ],
      "metadata": {
        "id": "VKNf8eoL6fB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "llQVDnRPGasQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove rows from data where `keywords` is only single empty space ' '**"
      ],
      "metadata": {
        "id": "2D3fL4paH9UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of rows where keywords are ' '\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "cCgDfhukIh-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where keywords are ' '\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "738XiGjaJ-4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove duplicates from data considering `transcription` and `keywords` columns**"
      ],
      "metadata": {
        "id": "YOe7SUKCY9Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check duplicates\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "HTrFn1dlZDAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA1d25HrzTGW"
      },
      "source": [
        "**Exercise 3: Display  all the categories of `medical_specialty` and their counts in the dataset [0.5 Mark]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C92ji6ZV9MWs"
      },
      "source": [
        "# Displaying the distinct categories of medical specialty\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total categories\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "kRxuMduGSWYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtIjY7ji9va5"
      },
      "source": [
        "# Displaying the distinct categories of medical specialty and the number of records belonging to each category\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyXtz0Mr0NVB"
      },
      "source": [
        "**Exercise 4: Create a pie plot depicting the percentage of `medical_specialty` distributions category-wise. [0.5 mark]**\n",
        "\n",
        "**Hint:** Use [plt.pie()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pie.html) and [plt.get_cmap](https://matplotlib.org/stable/tutorials/colors/colormaps.html) for color mapping the pie chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrpJDoGx-CuF"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-process `transcription` and `keywords` text\n",
        "\n",
        "**Exercise 5: Create functions to perform below tasks: [0.5 Mark]**\n",
        "\n",
        "- Convert transcription and keywords text to lowercase\n",
        "- Remove quotes from transcription and keywords text\n",
        "- Remove all the special characters/punctuations\n",
        "- Remove digits from transcription and keywords text\n",
        "- Remove extra spaces"
      ],
      "metadata": {
        "id": "YxjnEkqScZEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Convert `transcription` and `keywords` text to lowercase**"
      ],
      "metadata": {
        "id": "v0TfQlpjX7wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert transcription and keywords text to lowercase\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "2hrcz_N2X_4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove quotes from `transcription` and `keywords` text**"
      ],
      "metadata": {
        "id": "uVwGZWVbYDpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove quotes from transcription and keywords text\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "y3xdgaWoYO15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove punctuations**"
      ],
      "metadata": {
        "id": "qk1LsKqxYROe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuations\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "G5JWyMHmYcIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove digits from `transcription` and `keywords` text**"
      ],
      "metadata": {
        "id": "vrBG3WtaZL6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove digits from transcription and keywords sentences\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "k2fOQlyHZJ6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove extra spaces**"
      ],
      "metadata": {
        "id": "TVegB3M5aDJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove extra spaces\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Y1OyJG10Wh-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6: Remove the stopwords from `transcription` text [0.5 Mark]**"
      ],
      "metadata": {
        "id": "B7-PRe-Lb0mU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove stopwords**"
      ],
      "metadata": {
        "id": "3p57xUIMi5_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove the stopwords\n",
        "\n",
        "def remove_stopwords(text):\n",
        "\n",
        "    # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "WJrIowuVVmDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx1sxCTDNN_w"
      },
      "outputs": [],
      "source": [
        "# Remove stopwords from transcriptions\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[OPTIONAL]** Visualize the distribution of word counts in both `transcription` and `keywords` text.\n",
        "\n",
        "**Hint:**\n",
        "- Get the text length of each sample\n",
        "- pd.DataFrame().hist() OR sns.histplot()"
      ],
      "metadata": {
        "id": "pZbujV_ZyC7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p65AHp4ZNN_x"
      },
      "outputs": [],
      "source": [
        "# Visualize the distribution of word counts\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the maximum sequence length for both `transcription` and `keywords`"
      ],
      "metadata": {
        "id": "Z2CklO7-d1tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the maximum length of the transcript\n",
        "# Fix the maximum keywords length\n",
        "\n",
        "max_len_transcript = 250\n",
        "max_len_keywords = 30"
      ],
      "metadata": {
        "id": "FBvPpAp9KJtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 7: Add `'start'` and `'end'` to `keywords` text at the beginning and end respectively [0.5 Mark]**\n",
        "\n",
        "- 'start' will represent the beginning of output sequence\n",
        "- 'end' will represent the end of output sequence"
      ],
      "metadata": {
        "id": "5zPQnTSE3ftY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 'start' and 'end' to keywords text\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "W8W-aL32JIlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajaAr2XgeCii"
      },
      "source": [
        "### Split data into training and testing set\n",
        "\n",
        "- test_size=0.1\n",
        "- random_state=0\n",
        "- shuffle=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb-27FbLeCij"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization and padding"
      ],
      "metadata": {
        "id": "I1QlCkyn6JKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 8: Convert the `transcription` and `keywords` text to sequence of integer values, and make them of uniform length [0.5 Mark]**\n",
        "\n",
        "- Use two tokenizers to tokenize transcription and keywords separately\n",
        "  \n",
        "  **Hint:** [Tokenizer()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer), `.fit_on_texts()`, `.texts_to_sequences()`\n",
        "\n",
        "- Pad/Truncate both sequences as per their max sequence length specified in above exercises\n",
        "    - use padding='post', truncating='post'\n",
        "    - for transcription, (use maxlen= max_len_transcript)\n",
        "    - for keywords, (use maxlen= max_len_keywords + 1)\n",
        "\n",
        "  **Hint:** [`pad_sequences(`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)`sequences= , maxlen= , padding='post', truncating='post')`\n",
        "\n",
        "- For long keywords sequences, the 'end' token might get truncated\n",
        "    - replace the last token with the token index of 'end'\n",
        "\n",
        "- save the vocab size for both sequences"
      ],
      "metadata": {
        "id": "iSk9rUrxbJky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5TPQusbeCil"
      },
      "outputs": [],
      "source": [
        "# Instantiate tokenizer for transcripts\n",
        "x_tokenizer = Tokenizer()\n",
        "\n",
        "# Fit on training data\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Convert transcript sequences into integer sequences for both train and val set\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Add zero padding upto maximum length\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# x vocab size\n",
        "x_voc_size = len(x_tokenizer.word_index) +1\n",
        "x_voc_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Ppbw4XeCim"
      },
      "outputs": [],
      "source": [
        "# Instantiate tokenizer for keywords\n",
        "y_tokenizer = Tokenizer()\n",
        "\n",
        "# Fit on training data\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Convert keywords sequences into integer sequences for train and val set\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Add zero padding upto maximum length\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# y vocab size\n",
        "y_voc_size = len(y_tokenizer.word_index) +1\n",
        "y_voc_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **For long keywords sequences, replace the last token with the token index of 'end'**"
      ],
      "metadata": {
        "id": "HNOtw3f-k67g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_tokenizer.word_index['end'])"
      ],
      "metadata": {
        "id": "uPGFUtc85ZgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the last token with the token index of 'end' for long sequences\n",
        "\n",
        "# Apply on Train keywords set\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Apply on Validation keywords set\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "LNtAVcci5nY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Embedding\n",
        "\n",
        "**Exercise 9: Create a class, `PositionalEmbedding` [1 Mark]**\n",
        "\n",
        "- Use `mask_zero=True`, while defining token embeddings layer\n",
        "\n",
        "- Make sure to make this layer a mask-generating layer by adding a method `compute_mask()`"
      ],
      "metadata": {
        "id": "z804TTWnnpG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        # YOUR CODE HERE ...\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # YOUR CODE HERE ...\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def get_config(self):\n",
        "        # YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "EJFVFHXcnrMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Block\n",
        "\n",
        "**Exercise 10: Create a class, `TransformerEncoder` [1 Mark]**\n",
        "\n",
        "- While calling `attention` layer, do not use `attention_mask` parameter\n",
        "\n",
        "- In Feed forward network, add `Dropout(0.1)` layer after 2 dense layers\n",
        "\n",
        "- For skip connections, use `tf.keras.layers.Add()` instead of `'+'`"
      ],
      "metadata": {
        "id": "Nv61oM1lrOBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # YOUR CODE HERE ...\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        # YOUR CODE HERE ...\n",
        "\n",
        "    def get_config(self):\n",
        "        # YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "Qjs4oJvlrRI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder Block\n",
        "\n",
        "**Exercise 11: Create a class, `TransformerDecoder` [1 Mark]**\n",
        "\n",
        "- Do not create any separate function to get causal attention mask, just pass `use_causal_mask = True` parameter while calling `attention_1` layer\n",
        "\n",
        "- While calling `attention_2` layer, do not use `attention_mask` parameter\n",
        "\n",
        "- In Feed forward network, add `Dropout(0.1)` layer after 2 dense layers\n",
        "\n",
        "- For skip connections, use `tf.keras.layers.Add()` instead of `'+'`"
      ],
      "metadata": {
        "id": "KbAVK3wyuRf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # YOUR CODE HERE ...\n",
        "\n",
        "    def get_config(self):\n",
        "        # YOUR CODE HERE ...\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None): # two inputs: decoder i/p and encoder o/p\n",
        "\n",
        "        # YOUR CODE HERE ...\n"
      ],
      "metadata": {
        "id": "6hXHINBbuTW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Transformer model\n",
        "\n",
        "**Exercise 12: Create a transformer model with below points: [1 Mark]**\n",
        "\n",
        "- Use the respective vocabulary size for PositionalEmbedding of encode and decoder inputs\n",
        "\n",
        "- Add `Dropout(0.1)` layers after both encoder and decoder PositionalEmbedding layers\n",
        "\n",
        "- Do not use `activation=\"softmax\"` for the last dense classification layer (You will be required to create a custom loss, and metric in the next stage.)\n",
        "\n",
        "- Add a stack of 4 encoder blocks and 4 decoder blocks to your transformer"
      ],
      "metadata": {
        "id": "AiaXYTIpw2k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transformer model\n",
        "\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,))\n",
        "\n",
        "# YOUR CODE HERE ...\n",
        "\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,))\n",
        "\n",
        "# YOUR CODE HERE ...\n",
        "\n",
        "\n",
        "decoder_outputs = layers.Dense(y_voc_size)(x)\n",
        "\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer.summary()"
      ],
      "metadata": {
        "id": "UmHaiKyXw6oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Compilation and Training [1 Mark]"
      ],
      "metadata": {
        "id": "DeBvxrOqAohp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 13: Set up the optimizer**\n",
        "\n",
        "Refer [here](https://www.tensorflow.org/text/tutorials/transformer#set_up_the_optimizer) for the following steps:\n",
        "\n",
        "- Use the Adam optimizer with a custom learning rate scheduler\n",
        "\n",
        "- Instantiate the Adam optimizer with custom learning rate"
      ],
      "metadata": {
        "id": "1w-GHPylA0IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    # YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "fe7-5dDu1wfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Adam optimizer with custom learning rate\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "x2-tkPW21y-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 14: Set up the loss and metrics**\n",
        "\n",
        "- Apply a padding mask while calculating the loss with cross-entropy loss function as demonstrated [here](https://www.tensorflow.org/text/tutorials/transformer#set_up_the_loss_and_metrics).  "
      ],
      "metadata": {
        "id": "mMQ8zocJBWDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "    # YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "ts9shHt718CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 15: Compile transformer model with custom optimizer, loss, and metric & perform training [0.5 Mark]**\n",
        "\n",
        "- Use [*transcription sequences*, and *keywords sequences(shifted right)*] as input to transformer\n",
        "\n",
        "- Train model using colab's GPU runtime with batch_size=32, and epochs=30. (It might take one minute per epoch with GPU)\n",
        "\n",
        "**Hint:** Check if the training code is running without any errors with CPU runtime, later switch to GPU runtime for faster training. Once trained, save the model weights, and download into your system for later use."
      ],
      "metadata": {
        "id": "LXPo6NhRB42D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "9pgKetun1_9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "EIeka1thAUo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model weights"
      ],
      "metadata": {
        "id": "gZkETV7giEuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir my_model_weights"
      ],
      "metadata": {
        "id": "r3DV-yQihsNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "# It will create a '.weights.h5' file which can be downloaded into your system from colab\n",
        "\n",
        "transformer.save_weights('my_model_weights/my_weights.weights.h5')"
      ],
      "metadata": {
        "id": "u1Wfb5WJf_GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OR\n",
        "# Make a zip file, which also can be downloaded into your system from colab\n",
        "\n",
        "!zip -r 'my_model_weights.zip' 'my_model_weights'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9-Un2VAh6px",
        "outputId": "721a22b4-fdf7-47ed-a720-36b27dcb7b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: my_model_weights/ (stored 0%)\n",
            "  adding: my_model_weights/my_weights.weights.h5 (deflated 9%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model weights\n",
        "\n",
        "Whenever you need to use this trained model weights:\n",
        "* use the model architecture to create exact same model\n",
        "* then load the trained weights directly using below code"
      ],
      "metadata": {
        "id": "z0wjnHjRCU9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To load model weights\n",
        "#transformer.load_weights('my_model_weights/my_weights.weights.h5')"
      ],
      "metadata": {
        "id": "BoKEsIbqhWLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxKpqCbzSW6z"
      },
      "source": [
        "## Run Inference\n",
        "\n",
        "**Exercise 16: Create a function to extract keywords, given transcription text as input [1 Mark]**\n",
        "\n",
        "- Encode the input sentence using the Transcription tokenizer. This is the encoder input\n",
        "- Initialize decoder input with the 'start' token\n",
        "- The decoder then outputs the predictions by looking at the encoder output and its own output (self-attention).\n",
        "- Concatenate the predicted token to the decoder input and pass it to the decoder repeatedly\n",
        "- Make decoder predict the next token based on the previous tokens it has predicted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(sentence, transformer=transformer):\n",
        "\n",
        "    \"\"\" Takes an input sentence, and transformer. Returns extracted keywords. \"\"\"\n",
        "\n",
        "    # Convert input sentence into integer sequence (Note that tokenizer.texts_to_sequences() take list of text as input)\n",
        "    ip_tokens = # YOUR CODE HERE\n",
        "\n",
        "    # Add zero padding upto maximum length transcription\n",
        "    ip_tok_seq = # YOUR CODE HERE\n",
        "\n",
        "    # Create a decoder sequence with 'start' token index\n",
        "    dec_tok_seq = np.array([y_tokenizer.word_index['start']])\n",
        "\n",
        "    # Variable to store the output text string\n",
        "    keyword_sentence = ''\n",
        "\n",
        "    for i in range(max_len_keywords):\n",
        "\n",
        "        # Get output logits from transformer\n",
        "        pred = transformer([ip_tok_seq.reshape(1,-1), dec_tok_seq.reshape(1, -1)], training=False)\n",
        "        pred = pred[:, -1:, :]\n",
        "\n",
        "        # Select the index with max value from 'pred' to get the output token index\n",
        "        token = # YOUR CODE HERE\n",
        "\n",
        "        # Convert output token to word\n",
        "        word = y_tokenizer.index_word[token]\n",
        "\n",
        "        # End the loop if word is 'end'\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Append 'token' to dec_tok_seq\n",
        "        dec_tok_seq = np.append(dec_tok_seq, token)\n",
        "\n",
        "        # Append 'word' to keyword sentence\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    return keyword_sentence.strip()\n"
      ],
      "metadata": {
        "id": "lC282zeaCdtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict keywords for a sample input\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "QBf2v9SocE0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXQYvbik134w"
      },
      "source": [
        "## Gradio Implementation [OPTIONAL]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9LGFxtQjwxv"
      },
      "source": [
        "Gradio is an open-source python library that allows us to quickly create easy-to-use, customizable UI components for our ML model, any API, or any arbitrary function in just a few lines of code. We can integrate the GUI directly into the Python notebook, or we can share the link with anyone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl0ngdnKjKHH"
      },
      "outputs": [],
      "source": [
        "!pip -qq install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XwCJSdDDVVU"
      },
      "outputs": [],
      "source": [
        "import gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy_0yXHI7fs4"
      },
      "outputs": [],
      "source": [
        "# Input from user\n",
        "in_transcript = gradio.Textbox(lines=10, placeholder=None, value=\"transcription\", label='Enter Transcription Text')\n",
        "\n",
        "# Output prediction\n",
        "out_keywords = gradio.Textbox(type=\"text\", label='Extracted Keywords')\n",
        "\n",
        "\n",
        "# Gradio interface to generate UI\n",
        "iface = gradio.Interface(fn = extract_keywords,\n",
        "                         inputs = [in_transcript],\n",
        "                         outputs = [out_keywords],\n",
        "                         title = \"Keywords Extraction\",\n",
        "                         description = \"Using transformer model, trained from scratch\",\n",
        "                         allow_flagging = 'never')\n",
        "\n",
        "iface.launch(share = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2eQkcvnvntC"
      },
      "source": [
        "Click on the link generated above to see UI."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}