{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitchug/ALMlops/blob/main/Additional_NB_01_Train_Custom_NER_model_using_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Aditional Notebook: Build Custom NER using spaCy"
      ],
      "metadata": {
        "id": "zSstSEIv155v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* understand the spaCy library\n",
        "* train a custom Named Entity Recognition (NER) model using spaCy"
      ],
      "metadata": {
        "id": "akVZjBjD2PtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "VGel018GxQGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition (NER)** is one of the most pivotal data processing tasks in the field of NLP. It aims to locate and categorize key information, i.e., entities, in text data.  These ‘entities’ can be any word or any sequence of words that consistently refer to the same thing.\n",
        "\n",
        "At its core, entity recognition systems have two steps:\n",
        "\n",
        "- Detecting the entities in text\n",
        "- Categorizing the entities into named classes\n",
        "\n",
        "These categories change depending on the use case. Some of the most common entities classes are:\n",
        "\n",
        "- Person\n",
        "- Organization\n",
        "- Location\n",
        "- Time\n",
        "- Measurements or Quantities\n",
        "- String patterns like email addresses, phone numbers, or IP addresses"
      ],
      "metadata": {
        "id": "TI_iPJtzxSEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application of Named Entity Recognition:\n",
        "\n",
        "- Information Extraction And Summarization\n",
        "- Optimizing Search Engines\n",
        "- Machine Translation\n",
        "- Content Classification\n",
        "- Customer Support"
      ],
      "metadata": {
        "id": "GuwLBWnO3ima"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install packages"
      ],
      "metadata": {
        "id": "ysivBdlXMxoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy==3.7.4"
      ],
      "metadata": {
        "id": "RnmSjKExJ-AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "id": "NlHYHxmhJWqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above info, we can see that by default spaCy contains the small language model for the English language `en_core_web_sm`.\n",
        "\n",
        "To use medium, large, and transformer pre-trained models, they need to be installed first using the `!python -m spacy download` command."
      ],
      "metadata": {
        "id": "ioo8J8kk270t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install English transformer pipeline\n",
        "# NOTE that Runtime needs to restart after this step\n",
        "\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "enIOTr8y6hf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart the Runtime/Session**"
      ],
      "metadata": {
        "id": "HpB5KKWSKkby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "id": "x83z3TOfNGS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required packages"
      ],
      "metadata": {
        "id": "d6wPl_vwqL6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFOiNNeP0giN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import spacy\n",
        "from spacy import displacy             # to visualize/render text\n",
        "from spacy.tokens import DocBin        # to efficiently serializes the information from a collection of spacy's Doc objects\n",
        "from spacy.util import filter_spans    # to handle entity span overlaps\n",
        "from tqdm import tqdm                  # to make your loops show a smart progress meter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER in spaCy"
      ],
      "metadata": {
        "id": "OoRmCXB55X3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the spaCy pipeline loads the part-of-speech tagger, dependency parser, and NER."
      ],
      "metadata": {
        "id": "CqqpH5ut5yN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load transformer pipeline for English\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "id": "GGlQY8Ro2hw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a sample text\n",
        "text = \"On 3rd Feb, Ram was in Delhi.\\nLater he traveled to Mumbai via Air India flight reading a Time magazine to meet Raj.\\nAfter 10 days, he went again back to Delhi wearing a Timex watch.\"\n",
        "doc = nlp(text)\n",
        "spacy.displacy.render(doc, style='ent')"
      ],
      "metadata": {
        "id": "kZLngerFvbL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test another example of medical text:"
      ],
      "metadata": {
        "id": "CUe5dF4rQPiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize another sample text\n",
        "text2 = \"Antiretroviral therapy (ART) is recommended for all HIV-infected individuals to reduce the risk of disease progression.\"\n",
        "doc2 = nlp(text2)\n",
        "spacy.displacy.render(doc2, style='ent')"
      ],
      "metadata": {
        "id": "OLsKsMMgQRCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see that it doesn't perform that well on medical text data. For instance, if we try to extract entities from medical journal text it won't detect any relevant information.\n",
        "\n",
        "To solve this we'll need to train our own NER model. The process is very straightforward with spaCy."
      ],
      "metadata": {
        "id": "dx5NgU1HQrod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training custom NER model using spaCy"
      ],
      "metadata": {
        "id": "2NdRitT8329p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train our custom named entity recognition model, we will need some relevant text data with the proper annotations."
      ],
      "metadata": {
        "id": "Xh_gXGxU2bwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Description"
      ],
      "metadata": {
        "id": "DyFSDtg6H5ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Medical NER** [dataset](https://www.kaggle.com/datasets/finalepoch/medical-ner) is a manually tagged data (diseases, pathogens, and medication) for training NER system.\n",
        "\n",
        "This dataset was created to train a spaCy model to perform Named Entity Recognition for three categories:\n",
        "\n",
        "* ***Medical condition names*** (eg.: influenza, headache, malaria)\n",
        "* ***Medicine names*** (eg.: aspirin, penicillin, ribavirin, methotrexate)\n",
        "* ***Pathogens*** ( eg.: Corona Virus, Zika Virus, cynobacteria, E. Coli)"
      ],
      "metadata": {
        "id": "lEMkQ_RSGS8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the data\n",
        "!wget https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/Corona2.json\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Data downloaded successfully!\")\n",
        "!ls | grep '.json'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t85qwIrgQYUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Corona2.json file contains annotated text which was generated using [LightTag](https://www.lighttag.io/) online tool.\n",
        "\n",
        "Let's start by taking a look at the dataset."
      ],
      "metadata": {
        "id": "DhyNu2LXIV3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "wggqvbPJMbGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from json file\n",
        "\n",
        "with open('/content/Corona2.json', 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "_QIeRdwg21l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "id": "0LBjG64rKOno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples\n",
        "len(data['examples'])"
      ],
      "metadata": {
        "id": "6LMpDQTzKhiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample\n",
        "data['examples'][0]"
      ],
      "metadata": {
        "id": "GtksxtBq3y1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['examples'][0].keys()"
      ],
      "metadata": {
        "id": "cPWB_Mko4OiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['examples'][0]['content']"
      ],
      "metadata": {
        "id": "v9cdB6C99Jym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['examples'][0]['annotations'][0]"
      ],
      "metadata": {
        "id": "uQbKf0Ry9Opx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['examples'][0]['annotations'][0].keys()"
      ],
      "metadata": {
        "id": "_RFhdURhLG9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess data"
      ],
      "metadata": {
        "id": "1zOaLdboMjhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only need the `text` string, the entity `start` and `end` indices, and the entity `type`."
      ],
      "metadata": {
        "id": "mIsvIyThSzBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text string, entity start and end indices, and entity label\n",
        "\n",
        "training_data = []\n",
        "\n",
        "for example in data['examples']:\n",
        "    temp_dict = {}\n",
        "    temp_dict['text'] = example['content']             # text string\n",
        "    temp_dict['entities'] = []\n",
        "    for annotation in example['annotations']:\n",
        "        start = annotation['start']                    # entity start index\n",
        "        end = annotation['end']                        # entity end index\n",
        "        label = annotation['tag_name'].upper()         # entity label\n",
        "        temp_dict['entities'].append((start, end, label))\n",
        "    training_data.append(temp_dict)\n",
        "\n",
        "print(training_data[0])"
      ],
      "metadata": {
        "id": "gXS3_RsQ3PuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processed data for first sample\n",
        "training_data[0]['text']"
      ],
      "metadata": {
        "id": "oOvb8JZI3doC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracted entity details for first sample\n",
        "training_data[0]['entities']"
      ],
      "metadata": {
        "id": "a1vLiWdK3ma6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0]['text'][360:371]"
      ],
      "metadata": {
        "id": "vWYU8pQ83zmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy uses [*DocBin*](https://spacy.io/api/docbin) class for annotated data, so we'll have to create the *DocBin* objects for our training examples. This *DocBin* class efficiently serializes the information from a collection of *Doc* objects. It is faster and produces smaller data sizes than pickle, and allows the user to deserialize without executing arbitrary Python code."
      ],
      "metadata": {
        "id": "tWjk61H7TAte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Load a new spacy model\n",
        "nlp_blank = spacy.blank(\"en\")\n",
        "doc_bin = DocBin()"
      ],
      "metadata": {
        "id": "ZrbrxWEi3qLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some entity span overlaps, i.e., the indices of some entities overlap. spaCy provides a utility method [filter_spans](https://spacy.io/api/top-level#util.filter_spans) to deal with this."
      ],
      "metadata": {
        "id": "SM2B2lECTVu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from spacy.util import filter_spans\n",
        "\n",
        "for training_example in tqdm(training_data):\n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp_blank.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(f\"Skipping entity '{text[start:end]}'\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents\n",
        "    doc_bin.add(doc)\n",
        "\n",
        "doc_bin.to_disk(\"train.spacy\")"
      ],
      "metadata": {
        "id": "jBd4mdq039Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Configuration"
      ],
      "metadata": {
        "id": "XPF4rr36URTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training config files include all **settings and hyperparameters** for training your pipeline. Instead of providing lots of arguments on the command line, you only need to pass your `config.cfg` file to spacy train. This also makes it easy to integrate custom models and architectures, written in your framework of choice. A pipeline's `config.cfg` is considered the “single source of truth”, both at training and runtime.\n",
        "\n",
        "Let's initiallize a config file using `!python -m spacy init config` command. This command requires few arguments and options to specify:\n",
        "\n",
        "- ***output_file***: File to save the config to\n",
        "- ***lang***: Two-letter code of the language to use\n",
        "- ***pipeline***: Comma-separated names of trainable pipeline components to include\n",
        "- ***optimize***: Whether to optimize for efficiency (faster inference, smaller model, lower memory consumption) or higher accuracy (potentially larger and slower model)\n",
        "\n",
        "To know more about other config arguments, run `!python -m spacy init config --help` command."
      ],
      "metadata": {
        "id": "oVA6gjzUQ--T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
      ],
      "metadata": {
        "id": "4dEbtnOhReT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "jTy8xK6JTxQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./ --paths.train ./train.spacy --paths.dev ./train.spacy --nlp.batch_size 100 --training.max_epochs 25"
      ],
      "metadata": {
        "id": "BmWH1kM7TU4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "Let's load the best-performing model and test it on a piece of text."
      ],
      "metadata": {
        "id": "Qt6xBA6gTsnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "nlp_ner = spacy.load(\"model-best\")"
      ],
      "metadata": {
        "id": "uYfhbE013Hmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_ner(\"While bismuth compounds (Pepto-Bismol) decreased the number of bowel movements in those with travelers' diarrhea, they do not decrease the length of illness.[91] Anti-motility agents like loperamide are also effective at reducing the number of stools but not the duration of disease.[8] These agents should be used only if bloody diarrhea is not present.\")\n",
        "\n",
        "#colors = {\"PATHOGEN\": \"#F67DE3\", \"MEDICINE\": \"#7DF6D9\", \"MEDICALCONDITION\":\"#a6e22d\"}\n",
        "colors = {\"PATHOGEN\": \"yellow\", \"MEDICINE\": \"lightblue\", \"MEDICALCONDITION\":\"lightgreen\"}\n",
        "options = {\"colors\": colors}\n",
        "\n",
        "spacy.displacy.render(doc, style=\"ent\", options= options)"
      ],
      "metadata": {
        "id": "6eS0ZBS5E0U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test another example 3:**"
      ],
      "metadata": {
        "id": "3n2TO7fgVtuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize another sample text\n",
        "text2 = \"Antiretroviral therapy (ART) is recommended for all HIV-infected individuals to reduce the risk of disease progression.\"\n",
        "doc2 = nlp_ner(text2)\n",
        "\n",
        "colors = {\"PATHOGEN\": \"yellow\", \"MEDICINE\": \"lightblue\", \"MEDICALCONDITION\":\"lightgreen\"}\n",
        "options = {\"colors\": colors}\n",
        "\n",
        "spacy.displacy.render(doc2, style='ent', options= options)"
      ],
      "metadata": {
        "id": "4ymsOpJIh3CJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}