{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitchug/ALMlops/blob/main/M2_AST_02_CNN_Transfer_Learning_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Assignment 2: Leveraging a pre-trained model"
      ],
      "metadata": {
        "id": "2c2SSq-0fluo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "1. Understand and use a pre-trained model\n",
        "2. Fine-tune the top layers while using a pre-trained model\n"
      ],
      "metadata": {
        "id": "1IVfPFW_fwSY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsRvOU8bW3bj"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "A common and highly effective approach to deep learning on small image datasets is to use a pre-trained model.\n",
        "\n",
        "If the original dataset is large enough and general enough, the spatial hierarchy of features learned by the pre-trained model can effectively act as a generic model of the visual world, and hence, its features can prove useful for many different computer vision problems even though these new problems may involve completely different classes than those of the original task.\n",
        "\n",
        "There are two ways to use a pre-trained model:\n",
        "  * feature extraction and\n",
        "  * fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av8AYVUgXflR"
      },
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAe4IBm3YTDo"
      },
      "source": [
        "A CNN typically consists of a:\n",
        "* Convolutional base\n",
        "* Densely connected classifier\n",
        "\n",
        "Key Idea -\n",
        "* Features are learned by the convolutional base. So reuse it.\n",
        "* Train a new classifier for your problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NP5AuR09mow"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=12FzJVGUCzQGDArYSqdABntKwKGHzIjVX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WBPPuGmBlDIN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M2_AST_02_CNN_Transfer_Learning_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    # ipython.magic(\"wget https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/Acoustic_Extinguisher_Fire_Dataset.xlsx\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "Hf1qet2EgGcL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgPKI1GpnAn7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D,MaxPool2D\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seu6Ni2CX7CT"
      },
      "source": [
        "Let us reuse the VGG16 network which has been trained on the ImageNet, which contains multiple classes of cats and dogs among other things.\n",
        "\n",
        "We expect the convolution base to have learned features that help it identify cats and dogs.\n",
        "\n",
        "Keras provides us with a pre-trained VGG16 network!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "fcNilE95iILQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ExTNZyWnEx3"
      },
      "outputs": [],
      "source": [
        "# Load the convolutional base\n",
        "conv_base = VGG16(\n",
        "    weights = \"imagenet\",\n",
        "    include_top = False, # Don't re-use the classifier (top layers)\n",
        "    input_shape = (180,180,3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b9kdoqLnPKx"
      },
      "outputs": [],
      "source": [
        "# See a summary of the convolutional base\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UKbWJkUbMJt"
      },
      "source": [
        "So how do we extract the features? Simple:\n",
        "\n",
        "Pass the images through the convolutional base."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/cats_vs_dogs_small.zip\n",
        "!unzip -qq '/content/cats_vs_dogs_small.zip'"
      ],
      "metadata": {
        "id": "S-Wl6uFLjL3Y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining path names for futur use\n",
        "data_dir = '/content/cats_vs_dogs_small'\n",
        "\n",
        "train_path = data_dir + '/train'\n",
        "validation_path = data_dir + '/validation'\n",
        "test_path = data_dir + '/test'"
      ],
      "metadata": {
        "id": "rA46mBvMjORA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the image dataset into a workable format"
      ],
      "metadata": {
        "id": "K1JApk1OjbKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "hjXVr-IhjWkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passing the dataset through Conv Base i.e forward pass through pre-trained weights\n",
        "\n",
        "Before forward pass, Preprocessing the dataset specific to VGG16 is also required."
      ],
      "metadata": {
        "id": "JQ0gpF96nqkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input # Importing function for preprocessing specific to the vgg16"
      ],
      "metadata": {
        "id": "LqSbNdyUkIRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRw1G2rlnUG5"
      },
      "outputs": [],
      "source": [
        "# Extracting the features from pretrained models\n",
        "def get_features_and_labels(dataset):\n",
        "            # YOUR CODE HERE                                 # preprocessing specific to the vgg16\n",
        "            # YOUR CODE HERE                                 # forward pass\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "# Doing the same for all datasets\n",
        "train_feature, train_labels = get_features_and_labels(train_dataset)\n",
        "val_feature, val_labels = get_features_and_labels(validation_dataset)\n",
        "test_feature, test_labels = get_features_and_labels(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyAs3DUVntAy"
      },
      "source": [
        "### Defining and training the densely connected classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFHNlQaqnfo_"
      },
      "outputs": [],
      "source": [
        "# Q: Defining the classifier using the Functional API\n",
        "# YOUR CODE HERE\n",
        "model_without_conv_base = Model(inputs,outputs)  ## Model is imported from keras while importing libraries\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Call Back Function"
      ],
      "metadata": {
        "id": "gAY7NwrZM81q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "eFC5KcwnsyuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRjznrJmvYwE"
      },
      "outputs": [],
      "source": [
        "# Define a function to return a commmonly used callback_list\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YHU9VyboGQs"
      },
      "outputs": [],
      "source": [
        "# fit the densely connected classsifier\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Accuracy and Loss vs Epochs"
      ],
      "metadata": {
        "id": "oGFxlJVrqZZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwU7lbh_oML5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ohA0fCso6v3"
      },
      "outputs": [],
      "source": [
        "test_model = load_model(\"feature_extraction_keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_feature,test_labels)\n",
        "print(f\"Test accuracy:{test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5h2ONkvyZ2c"
      },
      "source": [
        "The pretrained conv base + newly trained classification head has achieved roughly **97%** accuracy!\n",
        "\n",
        "Remember, for convnet_from_scratch_with_data_augmentation, it was ~ 85%\n",
        "\n",
        "For convnet_from_scratch, it was ~ 70%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpBJf_wrzSTf"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DrZOdGXzVBN"
      },
      "source": [
        "The key idea here is to fine tune some top layers of the conv base as well.\n",
        "\n",
        "We do so by freezing most of the bottom layers, leaving only a few top layers to train. Lets see:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTjJMKK2zr5_"
      },
      "outputs": [],
      "source": [
        "# Load the convolutional base\n",
        "conv_base = VGG16(\n",
        "    weights = \"imagenet\",\n",
        "    include_top = False, # Don't re-use the classifier (top layers)\n",
        "    input_shape = (180,180,3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model\n",
        "inputs = Input(shape=(180, 180, 3))\n",
        "# x = data_augmentation(inputs)\n",
        "x = preprocess_input(inputs)\n",
        "x = conv_base(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "B75ct3dqmibj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "B9dnMykRt2vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing all layers until the fourth from the last\n",
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:   #[1,2,3,4,5,6,7,8,9]\n",
        "    layer.trainable = False\n",
        "\n",
        "#  Model compilation and summary\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "NQ387fN1mooT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Callback function\n",
        "callbacks = [ModelCheckpoint(filepath=\"fine_tuning_keras\", save_best_only=True, monitor=\"val_loss\")]"
      ],
      "metadata": {
        "id": "BhI6SuYim0Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=30, validation_data=validation_dataset, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "S_SJzWbGnQUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluation\n",
        "model = load_model(\"fine_tuning_keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n",
        "# OPTIONAL EXERCISE: plot the losses by using appropriate callbacks and tensorboard"
      ],
      "metadata": {
        "id": "F6L_SQlHnJj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBFUlWZwpMt5"
      },
      "source": [
        "# Using already run and saved models\n",
        "\n",
        "For this save the model checkpoints in your drive (download the checkpoints and save to drive) give that path while loading.\n",
        "\n",
        "Mount your G drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhrep95RpQ9B"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, you downloaded the `feature_extraction_keras` model and saved it in your drive inside a folder named 'model'. You can load it here like this:\n",
        "\n",
        "    model_saved_1 = load_model('/content/drive/MyDrive/model/feature_extraction_keras')"
      ],
      "metadata": {
        "id": "DC4PNMZGvOgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this case the file path is simply : '/content/feature_extraction_keras'"
      ],
      "metadata": {
        "id": "N4fBwcIYudkJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoNajzD7pntO"
      },
      "outputs": [],
      "source": [
        "model_fewa = load_model('/content/feature_extraction_keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dky0dGDqoew"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model_fewa.evaluate(test_feature, test_labels)\n",
        "print(f\"Test accuracy is:{test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzD_PIikOtew"
      },
      "source": [
        "Great! feature_extraction model has achieved **97%** accuracy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "outputs": [],
      "source": [
        "#@title  What is the main idea of transfer learning in deep learning? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"A) To train the pre-trained Convolutional Base (Conv_Base) from scratch on a new dataset or task.\", \"B) To use the pre-trained Convolutional Base (Conv_Base) as a feature extractor and add new layers to the top of the pre-trained model for fine-tuning on a new dataset or task.\", \"C) To use the pre-trained Convolutional Base (Conv_Base) as the only layers for the new dataset or task without any modifications.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ]
}