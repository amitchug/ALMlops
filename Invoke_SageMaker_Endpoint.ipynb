{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitchug/ALMlops/blob/main/Invoke_SageMaker_Endpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invoke SageMaker Endpoint"
      ],
      "metadata": {
        "id": "dKzCThpM7MAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install boto3      # Python SDK for interacting with AWS services"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeRKRyiJ7LnY",
        "outputId": "a8d692e5-50c4-42d4-9d78-669496062d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3"
      ],
      "metadata": {
        "id": "jYj9XZXQ5S_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Access key, and secret access key\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('access_key')\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('secret_key')\n",
        "\n",
        "# Root user & IAM user (specify policies )\n",
        "\n",
        "# Create IAM User -> Create access keys\n"
      ],
      "metadata": {
        "id": "kcHSd8vZ8Xrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "\n",
        "client = boto3.client(\"runtime.sagemaker\", region_name='ap-south-1')    # This initializes a boto3 client that allows you to interact with\n",
        "                                                                        # the Amazon SageMaker runtime service. The service is used to perform\n",
        "                                                                        # actions like invoking an endpoint for model inference.\n",
        "\n",
        "body = pd.DataFrame(\n",
        "    [[1, 'female', 30, 8.05, 'S', 3, 1, 'Mrs']]            # Features that will be passed to the model for prediction.\n",
        ").to_csv(header=False, index=False).encode(\"utf-8\")        # .encode(\"utf-8\"): The resulting CSV string is encoded to UTF-8.\n",
        "                                                           # This is necessary because SageMaker expects the data to be passed in bytes format.\n",
        "\n",
        "\n",
        "# The below method is used to invoke an endpoint deployed in Amazon SageMaker to perform inference (predicting results) based on the model.\n",
        "response = client.invoke_endpoint(\n",
        "    EndpointName=\"canvas-titanic-deployment\",\n",
        "    ContentType=\"text/csv\",                      # Specifies the type of input data being sent to the endpoint. In this case, it is in CSV format.\n",
        "    Body=body,\n",
        "    Accept=\"application/json\"                    # Specifies that the response from the endpoint should be in JSON format.\n",
        ")"
      ],
      "metadata": {
        "id": "myZ1bBlqD6h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j13RHvC6MZPQ",
        "outputId": "6518f8ef-917c-4235-ebff-e60cc20b5789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ResponseMetadata': {'RequestId': '02986b11-194c-4925-a615-7cce8902a337',\n",
              "  'HTTPStatusCode': 200,\n",
              "  'HTTPHeaders': {'x-amzn-requestid': '02986b11-194c-4925-a615-7cce8902a337',\n",
              "   'x-amzn-invoked-production-variant': 'canvas-model-variant-2024-12-21-06-20-17-052055',\n",
              "   'date': 'Sat, 21 Dec 2024 07:02:38 GMT',\n",
              "   'content-type': 'application/json',\n",
              "   'content-length': '165',\n",
              "   'connection': 'keep-alive'},\n",
              "  'RetryAttempts': 0},\n",
              " 'ContentType': 'application/json',\n",
              " 'InvokedProductionVariant': 'canvas-model-variant-2024-12-21-06-20-17-052055',\n",
              " 'Body': <botocore.response.StreamingBody at 0x7870fffbb610>}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = response['Body'].read().decode('utf-8')\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IQgUs_KRM6xL",
        "outputId": "1ecf500d-fac9-46ef-ecb7-5bfa73cf057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"predictions\": [{\"predicted_label\": \"1\", \"probability\": 0.9447951912879944, \"probabilities\": \"[0.055204808712005615, 0.9447951912879944]\", \"labels\": \"[\\'0\\', \\'1\\']\"}]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "output = json.loads(output)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_m6vCTZNHg8",
        "outputId": "5ef50815-0390-40a1-ff83-aa40ca5c7f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'predictions': [{'predicted_label': '1',\n",
              "   'probability': 0.9447951912879944,\n",
              "   'probabilities': '[0.055204808712005615, 0.9447951912879944]',\n",
              "   'labels': \"['0', '1']\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label = [\"No\", \"Yes\"][int(output['predictions'][0]['predicted_label'])]\n",
        "pred_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5i25tHApNRiK",
        "outputId": "0b663c2f-f5a4-415e-cbf1-1a60b4b6f468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Implementation"
      ],
      "metadata": {
        "id": "2Z6tuAkWLGBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soLJDSW4KtEr",
        "outputId": "1e39688b-df85-4136-a80e-84244fc34e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "_fibi1yJRTvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# UI - Input components\n",
        "in_Title = gradio.Radio([\"Mrs\", \"Master\", \"Miss\", \"Mr\", \"Other\"], type=\"value\", label='Title')\n",
        "in_Pclass = gradio.Radio([1, 2, 3], type=\"value\", label='Passenger class')\n",
        "in_Sex = gradio.Radio([\"male\", \"female\"], type=\"value\", label='Gender')\n",
        "in_Age = gradio.Textbox(lines=1, placeholder=None, value=\"14\", label='Age of the passenger in yrs')\n",
        "in_Fare = gradio.Textbox(lines=1, placeholder=None, value=\"29\", label='Passenger fare')\n",
        "in_Embarked = gradio.Radio([\"Southampton\", \"Cherbourg\", \"Queenstown\"], type=\"value\", label='Port of Embarkation')\n",
        "in_FamilySize = gradio.Textbox(lines=1, placeholder=None, value=\"0\", label='Family Size')\n",
        "in_Has_cabin = gradio.Radio([\"No\", \"Yes\"], type=\"index\", label='Has Cabin')\n",
        "\n",
        "\n",
        "# UI - Output component\n",
        "out_label = gradio.Textbox(type=\"text\", label='Survived', elem_id=\"out_textbox\")\n",
        "\n",
        "\n",
        "# Label prediction function\n",
        "def get_output_label(in_Pclass, in_Sex, in_Age, in_Fare, in_Embarked, in_FamilySize, in_Has_cabin, in_Title):\n",
        "\n",
        "    body = pd.DataFrame(\n",
        "        [[in_Pclass, in_Sex, in_Age, in_Fare, in_Embarked[0], in_FamilySize, in_Has_cabin, in_Title]]\n",
        "    ).to_csv(header=False, index=False).encode(\"utf-8\")\n",
        "\n",
        "    response = client.invoke_endpoint(\n",
        "        EndpointName=\"canvas-titanic-deployment\",\n",
        "        ContentType=\"text/csv\",\n",
        "        Body=body,\n",
        "        Accept=\"application/json\"\n",
        "    )\n",
        "\n",
        "    output = response['Body'].read().decode('utf-8')\n",
        "    output = json.loads(output)\n",
        "    pred_label = [\"No\", \"Yes\"][int(output['predictions'][0]['predicted_label'])]\n",
        "\n",
        "    return pred_label\n",
        "\n",
        "\n",
        "# Create Gradio interface object\n",
        "iface = gradio.Interface(fn = get_output_label,\n",
        "                         inputs = [in_Pclass, in_Sex, in_Age, in_Fare, in_Embarked, in_FamilySize, in_Has_cabin, in_Title],\n",
        "                         outputs = [out_label],\n",
        "                         title=\"Titanic Survival Prediction API ⛴\",\n",
        "                         description=\"Predictive model that answers the question: “What sort of people were more likely to survive?”\",\n",
        "                         flagging_mode='never'\n",
        "                         )\n",
        "\n",
        "# Launch gradio interface\n",
        "iface.launch()           # set debug=True for debugging.\n",
        "                         # set server_name = \"0.0.0.0\" and server_port = 7860 while launching it inside container.\n",
        "                         # default server_name = \"127.0.0.1\", and server_port = 7860"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "wnjv_KdR9VG_",
        "outputId": "5fea4cc5-2d5f-4600-d04c-9dbb81a12d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d6c0661d0fcc34c800.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d6c0661d0fcc34c800.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXX3FMTZPlyJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}